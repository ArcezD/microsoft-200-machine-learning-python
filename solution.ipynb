{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598318098799",
   "display_name": "Python 3.7.2 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ingest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importar la data mediante Pandas utilizando el metodo [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). Visualizar las primeras 10 filas del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dependencies\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://topcs.blob.core.windows.net/public/FlightData.csv'\n",
    "\n",
    "## load data from csv to dataframe\n",
    "df = pd.read_csv(url)\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another solution:\n",
    "\n",
    "Download csv\n",
    "```bash\n",
    "!curl https://topcs.blob.core.windows.net/public/FlightData.csv -o flightdata.csv\n",
    "```\n",
    "\n",
    "Load data from csv to dataframe\n",
    "```\n",
    "df = pd.read_csv('flightdata.csv')\n",
    "df.head(n=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analizar la data utilizando las herramientas de pandas para determinar el tipo de datos que se tienen disponibles en el dataset.\n",
    "- Determinar si existe data nula y el impacto que tiene para nuestro caso de uso.\n",
    "- Eliminar o completar la data nula de acuerdo al analisis previo.\n",
    "- Aplicar \"data [binning](https://en.wikipedia.org/wiki/Data_binning)\" y convertir variables categoricas a variables de indicador para procesar la data de previo al entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analize data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality of the dataframe.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data type of each column.\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check if there ir any null value\n",
    "if (df.isnull().values.any()):\n",
    "    print('Existen valores nulos')\n",
    "else:\n",
    "    print('No existen valores nulos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which values are null\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select data of last column 'Unnamed: 25' that is completely null\n",
    "df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove data of last column\n",
    "df = df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another solution:\n",
    "```\n",
    "df.drop(['Unnamed: 25'], axis =1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the output and confirm that column 26 ('Unnamed: 25') has disappeared from the DataFrame\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter just required columns to the model that we want to train and inspect output and to confirm nulls is greatly reduced\n",
    "df = df[['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'ORIGIN', 'DEST', 'CRS_DEP_TIME', 'ARR_DEL15']]\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review data with null values\n",
    "df[df.isnull().values.any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flights that were canceled or diverted are going to be treated as late\n",
    "df = df.fillna({'ARR_DEL15': 1})\n",
    "df.iloc[177:185]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bin departure times and add indicator columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply data [binning](https://en.wikipedia.org/wiki/Data_binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.loc[index, 'CRS_DEP_TIME'] = math.floor(row['CRS_DEP_TIME'] / 100)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply pandas [get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) to origin and destination airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['ORIGIN', 'DEST'])\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar la data procesada para entrenar un modelo capaz de 'predecir' las probabilidades de que un vuelo llegue a tiempo.\n",
    "- Dividir el set de datos en dator para entrenamiento y datos para prueba.\n",
    "- Utilizar [Sckit-learn](https://scikit-learn.org/stable/index.html) para entrenar el modelo.\n",
    "- Validar el nivel de precisi√≥n del modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe to use 80% per training and 20% for testing model\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(df.drop('ARR_DEL15', axis=1), df['ARR_DEL15'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows and columns in the DataFrame containing the feature columns used for training\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows and columns in the DataFrame containing the feature columns used for testing\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) algorithm for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=13)\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing model\n",
    "predicted = model.predict(test_x)\n",
    "model.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a set of prediction probabilities from the test data\n",
    "from sklearn.metrics import roc_auc_score\n",
    "probabilities = model.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an ROC AUC score from the probabilities using Sckit-learn's roc_auc_score method\n",
    "roc_auc_score(test_y, probabilities[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a confusion matrix (\"error matrix\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a precision_score for computing precision\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "train_predictions = model.predict(train_x)\n",
    "precision_score(train_y, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_score(train_y, train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilizar [Matplotlib](https://matplotlib.org/) para visualizar los resultados.\n",
    "- Crear funci√≥n para obtener probabilidad de atraso en vuelos para dias y horas especificos, as√≠ como origen y destinos especificos.\n",
    "- Graficar posibilidades de falso / positivo.\n",
    "- Graficar posibilidades de atraso para d√≠as especificos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, _ = roc_curve(test_y, probabilities[:, 1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], color='grey', lw=1, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_delay(departure_date_time, origin, destination):\n",
    "    from datetime import datetime\n",
    "\n",
    "    try:\n",
    "        departure_date_time_parsed = datetime.strptime(departure_date_time, '%d/%m/%Y %H:%M:%S')\n",
    "    except ValueError as e:\n",
    "        return 'Error parsing date/time - {}'.format(e)\n",
    "    \n",
    "    month = departure_date_time_parsed.month\n",
    "    day = departure_date_time_parsed.day\n",
    "    day_of_week = departure_date_time_parsed.isoweekday()\n",
    "    hour = departure_date_time_parsed.hour\n",
    "    \n",
    "    origin = origin.upper()\n",
    "    destination = destination.upper()\n",
    "\n",
    "    input = [{'MONTH': month,\n",
    "              'DAY': day,\n",
    "              'DAY_OF_WEEK': day_of_week,\n",
    "              'CRS_DEP_TIME': hour,\n",
    "              'ORIGIN_ATL': 1 if origin == 'ATL' else 0,\n",
    "              'ORIGIN_DTW': 1 if origin == 'DTW' else 0,\n",
    "              'ORIGIN_JFK': 1 if origin == 'JFK' else 0,\n",
    "              'ORIGIN_MSP': 1 if origin == 'MSP' else 0,\n",
    "              'ORIGIN_SEA': 1 if origin == 'SEA' else 0,\n",
    "              'DEST_ATL': 1 if destination == 'ATL' else 0,\n",
    "              'DEST_DTW': 1 if destination == 'DTW' else 0,\n",
    "              'DEST_JFK': 1 if destination == 'JFK' else 0,\n",
    "              'DEST_MSP': 1 if destination == 'MSP' else 0,\n",
    "              'DEST_SEA': 1 if destination == 'SEA' else 0 }]\n",
    "\n",
    "    return model.predict_proba(pd.DataFrame(input))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_delay('1/10/2018 21:45:00', 'JFK', 'ATL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_delay('2/10/2018 21:45:00', 'JFK', 'ATL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_delay('2/10/2018 10:00:00', 'ATL', 'SEA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the probability of on-time arrivals for an evening flight from JFK to ATL over a range of days\n",
    "import numpy as np\n",
    "\n",
    "labels = ('Oct 1', 'Oct 2', 'Oct 3', 'Oct 4', 'Oct 5', 'Oct 6', 'Oct 7')\n",
    "values = (predict_delay('1/10/2018 21:45:00', 'JFK', 'ATL'),\n",
    "          predict_delay('2/10/2018 21:45:00', 'JFK', 'ATL'),\n",
    "          predict_delay('3/10/2018 21:45:00', 'JFK', 'ATL'),\n",
    "          predict_delay('4/10/2018 21:45:00', 'JFK', 'ATL'),\n",
    "          predict_delay('5/10/2018 21:45:00', 'JFK', 'ATL'),\n",
    "          predict_delay('6/10/2018 21:45:00', 'JFK', 'ATL'),\n",
    "          predict_delay('7/10/2018 21:45:00', 'JFK', 'ATL'))\n",
    "alabels = np.arange(len(labels))\n",
    "\n",
    "plt.bar(alabels, values, align='center', alpha=0.5)\n",
    "plt.xticks(alabels, labels)\n",
    "plt.ylabel('Probability of On-Time Arrival')\n",
    "plt.ylim((0.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ('Apr 10', 'Apr 11', 'Apr 12', 'Apr 13', 'Apr 14', 'Apr 15', 'Apr 16')\n",
    "values = (predict_delay('10/4/2018 13:00:00', 'JFK', 'MSP'),\n",
    "          predict_delay('11/4/2018 13:00:00', 'JFK', 'MSP'),\n",
    "          predict_delay('12/4/2018 13:00:00', 'JFK', 'MSP'),\n",
    "          predict_delay('13/4/2018 13:00:00', 'JFK', 'MSP'),\n",
    "          predict_delay('14/4/2018 13:00:00', 'JFK', 'MSP'),\n",
    "          predict_delay('15/4/2018 13:00:00', 'JFK', 'MSP'),\n",
    "          predict_delay('16/4/2018 13:00:00', 'JFK', 'MSP'))\n",
    "alabels = np.arange(len(labels))\n",
    "\n",
    "plt.bar(alabels, values, align='center', alpha=0.5)\n",
    "plt.xticks(alabels, labels)\n",
    "plt.ylabel('Probability of On-Time Arrival')\n",
    "plt.ylim((0.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph the probability that flights leaving SEA for ATL at 9:00 a.m., noon, 3:00 p.m., 6:00 p.m., and 9:00 p.m. on January 30 will arrive on time.\n",
    "labels = ('9:00 a.m.', '12:00 m.d.', '3:00 p.m.', '6:00 p.m.', '9:00 p.m.')\n",
    "values = (predict_delay('30/01/2019 09:00:00', 'SEA', 'ATL'),\n",
    "          predict_delay('30/01/2019 12:00:00', 'SEA', 'ATL'),\n",
    "          predict_delay('30/01/2019 15:00:00', 'SEA', 'ATL'),\n",
    "          predict_delay('30/01/2019 18:00:00', 'SEA', 'ATL'),\n",
    "          predict_delay('30/01/2019 21:00:00', 'SEA', 'ATL'))\n",
    "alabels = np.arange(len(labels))\n",
    "\n",
    "plt.bar(alabels, values, align='center', alpha=0.5)\n",
    "plt.xticks(alabels, labels)\n",
    "plt.ylabel('Probability of On-Time Arrival')\n",
    "plt.ylim((0.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}